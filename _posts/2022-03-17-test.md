---
layout: post
title: "Test upload"
subtitle: "Abgabe AngStat"
background: '/img/posts/01.jpg'
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Angewandte Statitik: Abgabezettel 2

## Aufgabe 5: NWS

### Daten einlesen:
```{r}
miete<-read.csv("http://www.rolandlangrock.com/Abgabezettel/4106300Aufg2.csv")
attach(miete)
head(miete)
```

### a) Streudiagramm und Nadaraya-Watson Regressionsfunktion
```{r}
plot(alter, mietekalt, pch=19, bty="n", ylab="Kaltmiete", xlab="Alter der Wohnung")
NW = ksmooth(alter, mietekalt, kernel="normal", bandwidth=20)
lines(NW, lwd=2, col="cornflowerblue", add=TRUE)
```

### b) Konstante Fehlervarianz?
```{r}
prog = NW$y

epsilon = mietekalt - prog

plot(alter, epsilon, pch=19, bty="n", ylab="Epsilon", xlab="Alter der Wohnung")
abline(h=0, lwd=2, col=15)
```

Die Fehlervarianz scheint nicht konstant zu sein, besonders bei neuen Wohungen sind die Abweichungen der Epsilon größer, als bei älteren.

```{r}
mmod=lm(epsilon ~ alter + I(alter^2) + I(alter^3))
summary(mmod)

x=alter

plot(alter, epsilon, pch=19, bty="n", ylab="Epsilon", xlab="Alter der Wohnung")

curve(mmod$coefficients[1] + mmod$coefficients[2]*x + mmod$coefficients[3]*x^2 + mmod$coefficients[4]*x^3, add=TRUE, lwd=2, col=20)

curve(mmod$coefficients[1] + mmod$coefficients[2]*x + mmod$coefficients[3]*x^2 + mmod$coefficients[4]*x^3 + 500, add=TRUE, lwd=2, col="#87D9FF")

curve(mmod$coefficients[1] + mmod$coefficients[2]*x + mmod$coefficients[3]*x^2 + mmod$coefficients[4]*x^3 - 500, add=TRUE, lwd=2, col="#87D9FF")

```

Bei näherer Betrachtung scheint die Annahme der Homoskedastizität zwar verletzt, allerdings nicht in einem extremen Maß. Es ist zu erkennen, dass die Fehlervarianz bei neuen Wohnungen höher ist, als bei älteren Wohnungen.

### c) Over- und Underfitting
```{r}
plot(alter, mietekalt, pch=19, bty="n", ylab="Kaltmiete", xlab="Alter der Wohnung")

# 1. Overfitting
NW1 = ksmooth(alter, mietekalt, kernel="normal", bandwidth=3)
lines(NW1, lwd=2, col="#FF8A22", add=TRUE)

# 2. Underfitting
NW2 = ksmooth(alter, mietekalt, kernel="normal", bandwidth=100)
lines(NW2, lwd=2, col="#FF2F22", add=TRUE)

# 3. Angemessene Anpassungsgüte
NW3 = ksmooth(alter, mietekalt, kernel="normal", bandwidth=15)
lines(NW3, lwd=2, col="cornflowerblue", add=TRUE)

legend(40,2000,c("Overfitting (b=3)","Underfitting (b=100)","angemessene Anpassungsgüte (b=20)"),
       lwd=rep(2,3),lty=c(1,1,1),col=c("#FF8A22","#FF2F22","cornflowerblue"),bty="n")
```

### d) Berechnung des lokalen NWS "zu Fuß"
Mit Rechteckkern:
```{r}
b=5
mxhut <- function(alter_stelle){
  (sum(ifelse((alter >= alter_stelle - b/2) & (alter <= alter_stelle + b/2), 1 * mietekalt,0))) / (sum(ifelse((alter >= alter_stelle - b/2) & (alter <= alter_stelle + b/2), 1 ,0)))
  }

mxhut(75)
```
Ergebnissse grafisch überprüfen:
```{r}
plot(alter, mietekalt, pch=19, bty="n", ylab="Kaltmiete", xlab="Alter der Wohnung")
NWrecht = ksmooth(alter, mietekalt, kernel="box", bandwidth=5)
lines(NWrecht, lwd=2, col="cornflowerblue", add=TRUE)
abline(v=75, col=7, lwd=2)
abline(h=428.2857, col=7, lwd=2)
```

Der errechnete Wert ist nahe an dem Wert aus dem ksmooth-Funktion mit Rechteckkern und Bandweite 5.

### e) Bivariater lokaler NWS "zu Fuß"
```{r}
x = 30
y = 50

b1 = 15
b2 = 25

mxhat2 = (sum(dnorm((x-alter)/b1)*dnorm((y-wohnflaeche)/b2)*mietekalt))/
  (sum(dnorm((x-alter)/b1)*dnorm((y-wohnflaeche)/b2)))

mxhat2
```
Der Preis liegt extrem nah am Wert des errechneten NWS für eine Wohnung mit diesen Charakteristika. Da der NWS als eine Art lokaler Mittelwert (mit Gaußkern natürlich etwas komplizierter (gewichtet)) interpretiert werden kann, scheint der Mietpreis angemessen zu sein.

### f) Bivariater NWS "zu Fuß"

```{r}
b1 = 15
b2 = 25

x1 = seq(0, 140, by=2)
x2 = seq(20, 160, by=2)

NWS = matrix(NA, 71, 71)

for (i in 1:71){
  for (j in 1:71){
  NWS[i,j] = (sum(dnorm((x1[i]-alter)/b1)*dnorm((x2[j]-wohnflaeche)/b2)*mietekalt))/ 
    (sum(dnorm((x1[i]-alter)/b1)*dnorm((x2[j]-wohnflaeche)/b2)))
  }
}

res<-persp(x1,x2,NWS,theta=-35,phi=10,xlab="Alter",ylab="Wohnfläche",
           zlab="Kaltmiete",ticktype="detailed",col="cornflowerblue",zlim=c(0,2000))
points(trans3d(alter,wohnflaeche,mietekalt,pmat=res),col=1,pch=19,cex=0.5)
```

(Durch den Export in R-Markdown, wurde der Plot leider skaliert.)

Es ist ein Interaktionseffekt von Wohnfläche und Alter erkennbar. Der Zipfel links oben im Plot deutet darauf hin, dass besonders große und neue Wohnungen besonders teuer sind.

## Aufgabe 6: Smoothing Splines

### Daten einlesen:

```{r}
gehalt<-read.csv("http://www.rolandlangrock.com/Abgabezettel/4106300Aufg6.csv")
head(gehalt)
dim(gehalt)
attach(gehalt)
```
### a) Streudiagramm mit Smoothing-Splines

```{r}
library(npreg) #Paket installieren

plot(Alter, Einkommen, pch=19, bty="n")

modEK = ss(Alter, Einkommen)
lines(modEK, lwd=3, col="cornflowerblue")
abline(h=50000, lwd=1, col="grey")
abline(h=40000, lwd=1, col="grey")
abline(h=55000, lwd=1, col="grey")
```

Die Regressionsfunktion suggeriert, dass das erwartete Jahreseinkommen vom 20. bis zum 30. Lebensjahr von ca. 50.000 € auf ca. 40.000 € sinkt. Ca. ab dem 30. Lebensjahr steigt es dann wieder auf einen maximalen Wert von ca. 55.000 € mit etwa 53 Jahren. Danach nimmt es wieder etwas ab.
Etwas überraschend ist, dass das durchschnittliche Jahresgehalt zwischen 20 und 30 Jahren so hoch ist.

### b) Kreuzvalidierung

```{r}
n=length(Einkommen)
l = seq(0.00001,0.0001,by=0.00001)
l
nl = length(l)
CVl = rep(NA,nl)

for(k in 1:nl){
  CV = rep(NA,n)
  for(i in 1:n){
    modSS = ss(Alter[-i], Einkommen[-i], lambda = l[k])
    mcv = predict(modSS, x=Alter[i])$y
    CV[i] = (Einkommen[i]-mcv)^2
  }
  CVl[k] = sum(CV)
}
CVl
```

### c) Kreuzvalidierungskriterium grafisch dargestellt

```{r}
plot(l, CVl, type="l", xlab="lambda", lwd=2)
abline(v=0.00004, lwd=2, col="cornflowerblue")
```

Ein Wert von lambda = 0.00004 scheint hier für einen optimalen Bias-Varianz-Trade-off zu sorgen. Wir sehen eine nach unten geöffnete Parabel, es gibt also ein inneres Minimum der Kreuzvalidierung für ein ganz bestimmtes Lambda.
Wenn lambda sehr klein ist, dann ist die Varianz hoch und deshalb auch die Kreuzvalidierung hoch, da wir großer Fehler mit unserer Schätzung machen. Wenn lambda groß ist, dann ist der Bias groß und deshalb auch die KV, weil die vorhersagen eines Schätzers mit diesem Lambda wieder schlechter werden.

Es sollte also ein Trade-Off angestrebt werden. Die Kreuzvalidierung (CV) ist am niedrigsten für ein moderates Lambda (=0.0004) (Kompromiss).

### d) Parametrische Regression

Zuerst ist herauszufinden, welcher Polynomgrad benötigt wird, um eine ähnliche Modellgüte wie die Smoothing-Splines zu erreichen. Hierzu wurde nochmal die Regressionsfunktion der Splines gezeichnet.
```{r}
plot(Alter, Einkommen, pch=19, bty="n")

modEK = ss(Alter, Einkommen, lambda=0.00004)
lines(modEK, lwd=2, col="cornflowerblue")
```

Die Regressionsfunktion mit dem optimalen Parameterwert für Lambda weisen eine doppelte Krümmung auf. Es muss also mindestens ein Polynom 3. Ordnung gewählt werden, um den Zusammenhang ähnlich darzustellen.

```{r}
lmod1 = lm(Einkommen ~ Alter + I(Alter^2) + I(Alter^3))
summary(lmod1)
```
Alle Koeffizienten sind signifikant. Es wird noch überprüft, ob sich auch ein Polynom vierter Ordnung zur Modellierung eignet:
```{r}
lmod2 = lm(Einkommen ~ Alter + I(Alter^2) + I(Alter^3) + I(Alter^4))
summary(lmod2)
```
Bei einem Polynom vierter Ordnung sind nur noch wenige Koeffizienten überhaupt signifikant, es ist also das Polynom dritter Ordnung vorzuziehen.
Dieses eben geschätzte Modell kann auch eingezeichnet werden:
```{r}
plot(Alter, Einkommen, pch=19, bty="n")

modEK = ss(Alter, Einkommen, lambda=0.00004)
lines(modEK, lwd=2, col="cornflowerblue")

curve(lmod1$coefficients[1] + lmod1$coefficients[2]*x + lmod1$coefficients[3]*x^2 + lmod1$coefficients[4]*x^3, 
      lwd=2, col=14, add=TRUE)
```
Die Smoothing-Splines und das Polynom dritter Ornung haben einen extrem ähnlichen Verlauf. Allein grafisch kann also schon auf eine ähnliche Güte geschlossen werden. Allerdings kann diese auch anhand der Kreuzvalidierung exakt überprüft werden:

```{r}
n=length(Einkommen)
CV = rep(NA,n)
for(i in 1:n){
  modSS = ss(Alter[-i], Einkommen[-i], lambda = 0.00004)
  mcv = predict(modSS, x=Alter[i])$y
  CV[i] = (Einkommen[i]-mcv)^2
}
CVsplines = sum(CV)
CVsplines
```
```{r}
CVl = rep(NA,n)
for(i in 1:n){
  lmod = lm(Einkommen[-i] ~ Alter[-i] + I(Alter[-i]^2) + I(Alter[-i]^3))
  mcvlm = lmod$coefficients[1] + lmod$coefficients[2]*Alter[i] + lmod$coefficients[3]*Alter[i]^2 + lmod$coefficients[4]*Alter[i]^3
  CVl[i] = (Einkommen[i]-mcvlm)^2
}
CVlm = sum(CVl)
CVlm
```
Auch hinsichtlich der Kreuzvalidierung weisen die Modelle eine ähnliche Anpassungsgüte auf. Überraschenderweise schneidet das Polynom sogar etwas besser ab, da der Wert der Kreuzvalidierung etwas geringer ausfällt.

## Aufgabe 7: Modellwahl

### Daten einlesen:

```{r}
med<-read.csv("http://www.rolandlangrock.com/Abgabezettel/4106300Aufg7.csv")
head(med)
dim(med)
attach(med)
```

### a) Anpassen eines logistischen Regressionsmodells mit Zielvariable "Krebs"

```{r}
modkrebs = glm(Krebs ~ Radius + Dichte + Homogenitaet, family=binomial)
summary(modkrebs)
```
Gemäß der Gaußtests ist nur die Variable Radius relevant, diese ist allerdings stark signifikant. Der Einfluss von Dichte und Homogenität ist nicht signifikant, da diese p-Werte von 0.0899 und 0.0611 haben. Diese beiden Variablen haben also keinen signifikanten Effekt auf das Krebsrisiko. Die T-Test verwerfen also zum Signifikanzniveau von 5 % nicht die Nullhypothese, dass diese keinen Einfluss auf die Zielvariable haben.

### b) Prognose
Einsetzen in die Regressionsfunktion:
```{r}
plogis(modkrebs$coefficients[1]+modkrebs$coefficients[2]*12.551+modkrebs$coefficients[3]*0.098+modkrebs$coefficients[4]*0.129)
```
Die Wahrscheinlichkeit, dass diese Person Krebs hat liegt gemäß dem Modell bei ca. 50 %.

### c) 

### Rückwärtsselektion

1. Volles Modell
```{r}
modkrebs1 = glm(Krebs ~ Radius + Dichte + Homogenitaet, family=binomial)
summary(modkrebs1)
```
Die am wenigsten relevante Variable ist Dichte mit einem P-Wert von 0.0899. Somit wird Dichte aus dem Modell entfernt.

2. Modell mit Radius und Homogenität
```{r}
modkrebs2 = glm(Krebs ~ Radius + Homogenitaet, family=binomial)
summary(modkrebs2)
```
Nun sind alle Variablen signifikant.
Das beste Modell ist also: Krebs[i] ~ Bern(Pi[i]) wobei Pi[i] = logit^-1(ß0 + ß1 Radius + ß2 Homogenitaet)

### Vorwärtsselektion

1. Leeres Modell
```{r}
modkrebs3 = glm(Krebs ~ 1,family=binomial)
summary(modkrebs3)
```
Keine Variable ist signifikant. Allerdings werden trotzdem Variablen aufgenommen.

2. Relevanteste Variable finden
```{r}
modkrebs4 = glm(Krebs ~ Radius,family=binomial)
summary(modkrebs4)
```
```{r}
modkrebs4_1 = glm(Krebs ~ Dichte,family=binomial)
summary(modkrebs4_1)
```
```{r}
modkrebs4_2 = glm(Krebs ~ Homogenitaet,family=binomial)
summary(modkrebs4_2)
```
In diesen drei Modellen erzielt die Variable Radius den kleinsten P-Wert und sollte demnach zuerst in das Modell aufgenommen werden.

Nun ist zwischen der Aufnahme von Dichte und Homogenität zu wählen.
```{r}
modkrebs5 = glm(Krebs ~ Radius + Dichte,family=binomial)
summary(modkrebs5)
```
```{r}
modkrebs5_1 = glm(Krebs ~ Radius + Homogenitaet,family=binomial)
summary(modkrebs5_1)
```
Die Variable Dichte erzielt einen geringeren P-Wert als die Variable Homogenitaet und sollte demnach aufgenommen werden.

Nun wird noch einmal das volle Modell geschätzt. 
```{r}
modkrebs6 = glm(Krebs ~ Radius + Dichte + Homogenitaet,family=binomial)
summary(modkrebs6)
```
Da Dichte und Homogenitaet nicht mehr signifikant sind, ist das vorherige Modell zu wählen. 
Das beste Modell ist also: Krebs[i] ~ Bern(Pi[i]) wobei Pi[i] = logit^-1(ß0 + ß1 Radius + ß2 Dichte)

Es fällt auf, dass wir ein unterschiedliches Ergebnis, je nach Selektionsverfahren erhalten. Während die Rückwärtsselektion das Modell mit ... ß0 + ß1Radius + ß2Homogenitaet präferiert, so präferiert die Vorwärtsselektion das Modell ... ß0 + ß1Radius + ß2Dichte.
Die Entscheidung welches Modell gewählt werden sollte, hängt also vom Modellierer ab, bzw. sollten noch andere Verfahren zur Modellwahl zum Einsatz kommen.

### d) Berechnung der Log-Likelihood und des AIC "zu Fuß"

Zuerst Vektor mit Pi's unter dem Modell berechnen:
```{r}
pis = plogis(modkrebs$coefficients[1]+modkrebs$coefficients[2]*Radius+modkrebs$coefficients[3]*Dichte+modkrebs$coefficients[4]*Homogenitaet)
```

Dann die Log-Likelihood als Summe der logarithmierten, Bernoulli-verteilten Zufallsvariablen Krebs[i] mit Eintrittswahrscheinlich Pi[i] berechnen:
```{r}
logLikelihood = sum(log(dbinom(Krebs,1,pis)))
logLikelihood
```
Überprüfung:
```{r}
logLik(modkrebs)
```
Nun per Hand das AIC berechnen (Formel auf Slide 273):
```{r}
AIC = (-2)*logLikelihood + 2*4 #4 Koeffizienten
AIC
```
Überprüfung:
```{r}
AIC(modkrebs)
```

### e)

Da wir 3 potentielle Variablen haben, die entweder ins Modell aufgenommen werden oder nicht ergeben sich folgende 2^3=8 mögliche Modelle:

```{r}
modk0 = glm(Krebs ~ 1, family=binomial)
modk1 = glm(Krebs ~ Radius, family=binomial)
modk2 = glm(Krebs ~ Dichte, family=binomial)
modk3 = glm(Krebs ~ Homogenitaet, family=binomial)
modk4 = glm(Krebs ~ Radius + Dichte, family=binomial)
modk5 = glm(Krebs ~ Radius + Homogenitaet, family=binomial)
modk6 = glm(Krebs ~ Dichte + Homogenitaet, family=binomial)
modk7 = glm(Krebs ~ Radius + Dichte + Homogenitaet, family=binomial)
```
Und somit folgende AICs:
```{r}
AIC(modk0)
AIC(modk1)
AIC(modk2)
AIC(modk3)
AIC(modk4)
AIC(modk5)
AIC(modk6)
AIC(modk7)
```
Unter Berücksichtigung des AIC als Modellwahlkriterium ist das volle Modell mit allen linearen Prädiktoren auszuwählen, da dies zu einem minimalen AIC von 100.77 führt.

### f)
Nun gibt es 6 Mögliche Variablen:
Radius
- Dichte
- Homogenitaet
- Radius*Dichte
- Radius*Homogenitaet
- Dichte*Homogenitaet

Insgesamt also 2^6 = 64 mögliche Modelle

Das Beste Modell wird in starker Anlehnung an das Verfahren von Herrn Prof. Langrock ermittelt:

Zuerst Implementierung der Funktion zur Umrechnung von Zahlen ins Binärsystem.
Dann durchlaufen aller 64 möglichen Modelle per For-Schleife und jedes Mal Berechnung des AIC sowie ordnen der AICs und ausgeben der zugehörigen Binärzahl zu dem Modell mit dem geringsten AIC: 
```{r}
number2binary<-function(number,noBits){
  binary_vector<-rev(as.numeric(intToBits(number)))
  binary_vector[-(1:(length(binary_vector)-noBits))]
}

AICs<-rep(NA,64)
for (k in 0:63){
  b<-number2binary(k,6)
  modkrebs_<-glm(Krebs ~ I(b[1]*Radius)+I(b[2]*Dichte)+I(b[3]*Homogenitaet)+
             I(b[4]*(Radius*Dichte))+I(b[5]*(Radius*Homogenitaet)) + I(b[6]*(Dichte*Homogenitaet)), family=binomial)
  AICs[k+1]<-modkrebs_$aic
}
AICs

number2binary(order(AICs)[1]-1,6)
```
Das Modell mit dem minimalen AIC ist: Krebs[i] ~ Bern(Pi[i]) wobei Pi[i] = logit^-1(ß0 + ß1Radius + ß2RadiusDichte + ß3DichteHomogenitaet.

## Aufgabe 4: Grünen-Wähler:innen

### Daten einlesen:
```{r}
wahl2005<-read.csv("http://www.rolandlangrock.com/Abgabezettel/4106300Aufg8.csv")
head(wahl2005)
dim(wahl2005)
attach(wahl2005)
```

### 1) Explorative Datenanalyse

Zunächst Gesamtstimmanteil 2005 bestimmen
```{r}
anteilges = sum(waehleGruen) / length(waehleGruen)
anteilges
```

Dann den Stimmanteil für Frauen und Männer einzeln bestimmen, um mögliche Unterschiede zu erkennen.

```{r}
# Stimmanteil unter Frauen:
sum(waehleGruen[Weiblich==1]) / length(waehleGruen[Weiblich==1])

# Stimmanteil unter Männern:
sum(waehleGruen[Weiblich==0])/ length(waehleGruen[Weiblich==0])
```

Der Anteil Grünwählern unter Männern ist deutlich geringer als unter Frauen. Es ist also von einem positiven Einfluss von "Weiblich" auf die Wahrscheinlichkeit grün zu wählen auszugehen, und diese Variable sollte auf jeden Fall bei der Modellwahl berücksichtigt werden.

Aufteilung des Datensatzes in Grünenwähler:innen und Nichtgrünenwählern:innen sowie Erstellung eines Boxplots zur Visualiserung möglicher Einkommensunterschiede:


```{r}
gruenwaehler <- wahl2005[which(waehleGruen==1),]
nichtgruenwaehler <- wahl2005[which(waehleGruen==0),]

par(mfrow=c(1,2))
# Vergleich der Einkommen von Wähler:innnen der Grünen und anderer Parteien.
boxplot(exp(nichtgruenwaehler$logEinkommen), pch=16, ylab="Einkommen", ylim=c(0,360), xlab="Nicht-Grün")
boxplot(exp(gruenwaehler$logEinkommen), pch=16, ylim=c(0,360), xlab="Grün")
```


Es scheint Unterschiede zwischen der Einkommenshöhe von Grünwähler:innen und Nicht-Grünwähler:innen zu geben. Der Boxplot suggeriert, dass die der Median sowie die Quartile des Einkommens von Grünwähler:innen etwas höher liegt, als von Wähler:innen anderen Parteien. Allerdings ist auch erkennbar, dass besonders wohlhabende Menschen eher nicht die Grünen zu wählen scheinen. Da das Histogramm die Daten aber sehr reduziert sollten weitere Instrumente genutzt werden, um einen ersten Eindruck zu erhalten.

#### Histogramme
Untersuchen des Effekts der Variable Einkommen auf die Wahrscheinlichkeit die Grünen zu wählen. Hierzu Erstellung von zwei Histogrammen mit Kerndichteschätzungen, um nenneswerte Unterschiede bzgl. des Einkommens zwischen Grünenwähler:innen und Nichtgrünenwähler:innen festzustellen.

```{r}
gruenwaehler <- wahl2005[which(waehleGruen==1),]
nichtgruenwaehler <- wahl2005[which(waehleGruen==0),]

hist(gruenwaehler$logEinkommen, prob=TRUE, breaks=seq(1,6,0.5), ylim=c(0,0.8),
     main="Einkommensverteilung von Grünwählern", xlab="log(Einkommen)", col="#1fa12d")
lines(density(gruenwaehler$logEinkommen),lwd=2, col=1, add=TRUE)

hist(nichtgruenwaehler$logEinkommen, prob=TRUE, breaks=seq(1,6,0.5),ylim=c(0,0.8),
     main="Einkommensverteilung von Nicht-Grünwählern", xlab="log(Einkommen)")
lines(density(nichtgruenwaehler$logEinkommen),lwd=2, col=1, add=TRUE)
```
```{r}
exp(2.5)
exp(3.5)
exp(4)
exp(5)
```

Es ist ein moderater Unterschied zu erkennen. Ein großer Unteschied liegt in der Einkommensklasse von 12.000 € bis 33.000 €. In dieser Einkommensklasse wählen besonders viele Menschen nicht die Grünen. Es ist auch zu erkennen, dass der wohl größte Unterschied in der Einkommensklasse 33.000 - 55.000 € liegt.Hier wählen besonders viele Menschen Grün. Bei Einkommen ab 55.000 € wählen eher weniger Menschen grün. Insgesamt ist also ein klarer Effekt des Einkommens auf Wahrscheinlichkeit Grün zu wählen zu erkennen. Dieser Zusammenhang scheint allerdings nicht linear zu sein.

Um diesen komplexen Zusammenhang genauer zu untersuchen wurde zusammen mit einem (zugegebenermaßen nicht empfohlenen) Streudiagramm ein Smoothing-Spline geschätzt.

```{r}
plot(logEinkommen, waehleGruen, pch=19, bty="n", xlab="logarithmiertes Einkommen", ylab="Wahrscheinlichkeit die Grünen zu wählen")
lines(ss(logEinkommen, waehleGruen), lwd=2, col="#1fa12d")
abline(h=anteilges)
```
Der Verdacht verstärkt sich, dass es sich um einen komplexen Zusammenhang handelt, bei dem Menschen, aus niedrigen und besonders hohen Einkommensklassen unterdurchschnittlich oft die Grünen wählen, während besonders in der mittleren Einkommensklasse überdurchschnittlich oft Grün gewählt wird.
Der sehr hohe Anteil an Grün Wählern bei sehr einkommensschwachen Menschen ist wahrscheinlich darauf 
zurückzuführen, dass nur sehr junge Menschen ein derart niedriges Einkommen haben, diese aber überdurchschnittlich oft Grün wählen. Ein Interaktionseffekt zwischen Einkommen und Alter könnte also auch relevant sein.

#### Untersuchen des Effekts von Alter auf die Wahrscheinlichkeit grün zu wählen.
Hierfür wurde eine andere Darstellungsweise der Histogramme gewählt. Auf der y-Achse sind nun die absoluten 
Häufigkeiten abgebildet, und die Histogramme übereinander gelegt.
```{r}
hist(nichtgruenwaehler$Alter, ylim=c(0,700), main="Alter von Grünwählern und Nicht-Grünwählern",
     ylab="Anzahl in der Stichprobe", xlab="Alter")
hist(gruenwaehler$Alter, ylim=c(0,700), add=T, col="#1fa12d")
```
Zusätzlich können die Histogramme auch einzeln mit Kerndichteschätzung betrachtet werden.
```{r}
hist(Alter, prob=TRUE, ylim=c(0,0.05), main="Dichte nach Altersklassen", ylab="Dichte")
```
```{r}
hist(Alter, prob=TRUE, ylim=c(0,0.05), main="Dichte nach Altersklassen", ylab="Dichte")
hist(gruenwaehler$Alter, prob=TRUE, add=T, col="#1fa12d", ylab=c(0,0.5))
lines(density(gruenwaehler$Alter),lwd=2)
```
Gerade im ersten Plot zeigt sich in Bezug auf das Alter ein klarerer Zusammenhang. Es ist schnell zu erkennen, dass deutlich mehr jüngere Leute Grün wählen als ältere. In der Stichprobe geht die Anzahl ab 80 recht schnell gegen 0. Es ist also ein negativer Zusammenhang zwischen dem Alter und der Wahrscheinlichkeit grün zu wählen zu erwarten.

Anhand eines zugegebenermaßen nicht empfohlenen Streudiagramms mit Smoothing-Spline lässt sich dieser Verdacht untermauern. Es zeigt sich ein negativer, aber nichtlinearer Zusammenhang zwischen Alter und der Wahrscheinlichkeit grün zu wählen.

```{r}
plot(Alter,waehleGruen, pch=19, bty="n", ylab="Wahrscheinlichkeit die Grünen zu Wählen", main="Streudiagramm mit Smoothing-Splines")
lines(ss(Alter, waehleGruen), lwd=2, col="#1fa12d")
```

#### Alternative Betrachtungsweise über Anteil der Wähler:innen nach Klassen

#### 1. Alter

```{r}
anteil_u30 = sum(waehleGruen[Alter<30]) / length(waehleGruen[Alter<30])
anteil_u40 = sum(waehleGruen[Alter>=30 & Alter<40]) / length(waehleGruen[Alter>=30 & Alter<40])
anteil_u50 = sum(waehleGruen[Alter>=40 & Alter<50]) / length(waehleGruen[Alter>=40 & Alter<50])
anteil_u60 = sum(waehleGruen[Alter>=50 & Alter<60]) / length(waehleGruen[Alter>=50 & Alter<60])
anteil_u70 = sum(waehleGruen[Alter>=60 & Alter<70]) / length(waehleGruen[Alter>=60 & Alter<70])
anteil_u80 = sum(waehleGruen[Alter>=70 & Alter<80]) / length(waehleGruen[Alter>=70 & Alter<80])
anteil_u90 = sum(waehleGruen[Alter>=80 & Alter<90]) / length(waehleGruen[Alter>=80 & Alter<90])
anteil_u100 = sum(waehleGruen[Alter>=90 & Alter<100]) / length(waehleGruen[Alter>=90 & Alter<100])

alterabstuf = c(30,40,50,60,70,80,90,100)
anteilgruen = c(anteil_u30,anteil_u40,anteil_u50,anteil_u60,anteil_u70,anteil_u80,anteil_u90,anteil_u100)

plot(alterabstuf, anteilgruen, pch=19, bty="n", ylab="Anteil Grünwähler:innen", 
     xlab="Alter(30 = 20-29) usw.", main="Anteil Grünwähler:innen nach Altersklassen")
lines(ss(alterabstuf, anteilgruen, lambda=0.0001), lwd=2, col="#1fa12d")
```


Es zeigt sich ein nichtlinearer Einfluss von Alter den Anteil der Grünwähler in der Altersgruppe. Somit sollte auch ein solcher bei der Modellwahl berücksichtigt werden.

#### 2. Einkommen

```{r}
anteil_eink_u2 = sum(waehleGruen[logEinkommen<2]) / length(waehleGruen[logEinkommen<2])
anteil_eink_u3 = sum(waehleGruen[logEinkommen>=2 & logEinkommen<3]) / length(waehleGruen[logEinkommen>=2 & logEinkommen<3])
anteil_eink_u4 = sum(waehleGruen[logEinkommen>=3 & logEinkommen<4]) / length(waehleGruen[logEinkommen>=3 & logEinkommen<4])
anteil_eink_u5 = sum(waehleGruen[logEinkommen>=4 & logEinkommen<5]) / length(waehleGruen[logEinkommen>=4 & logEinkommen<5])
anteil_eink_u6 = sum(waehleGruen[logEinkommen>=5 & logEinkommen<6]) / length(waehleGruen[logEinkommen>=5 & logEinkommen<6])

einkommensabstuf = c(2,3,4,5,6)
anteileinkomm = c(anteil_eink_u2,anteil_eink_u3,anteil_eink_u4,anteil_eink_u5,anteil_eink_u6)

plot(einkommensabstuf, anteileinkomm, pch=19, bty="n", ylab="Anteil Grünwähler:innen", 
     xlab="Logarithmiertes Einkommen", main="Anteil Grünwähler:innen nach Einkommensklassen")
lines(ss(einkommensabstuf, anteileinkomm, lambda=0.00005), lwd=2, col="#1fa12d")
```

Der bereits gefundene/ beschriebene Zusammenhang bestätigt sich nochmals. Besonders Einkommensschwache Menschen sowie Menschen mit mittlerem Einkommen (obere Mittelschicht), scheinen besonders häufig Grün zu wählen. Wohingegen Menschen mit relative geringem und sehr hohem Einkommen besonders selten die Grünen wählen.

Zur Modellierung dieses komplexen Verlaufs scheint ein Polynom dritten Grades sinnvoll.

```{r}
plot(logEinkommen,waehleGruen, pch=19, bty="n", main="Streudiagramm linearem Modell", ylab="Wahrscheinlichkeit Grün zu wählen", xlab="logarithmiertes Einkommen")
x=logEinkommen
modeink = glm(waehleGruen ~ logEinkommen + I(logEinkommen^2) + I(logEinkommen^3), family=binomial)
summary(modeink)
curve(plogis(modeink$coefficients[1] + modeink$coefficients[2]*x + modeink$coefficients[3]*x^2 + modeink$coefficients[4]*x^3), 
      add=TRUE, lwd=2, col="cornflowerblue")
```

Dies bestätigt sich durch die Schätzung einer logistischen Regression, die einzig das logarithmierte Einkommen zur Erklärung der Wahrscheinlichkeit Grün zu wählen nutzt.

### 2) Formulierung der Modellgleichungen

![Modellgleichungen](/Users/jan-ole/Modell.jpeg)

### 3) Schätzung der beiden Modelle und Modellwahl

#### Parametrische Regression:

Es wird ein logistisches Regressionsmodell geschätzt. Um ein Modell zu finden, dass möglichst gut zu den Daten passt, wird die Rückwärtsselektion angewandt.

```{r}
modgruen1 = glm(waehleGruen ~ Weiblich + Alter + I(Alter^2) + I(Alter^3) + logEinkommen + I(logEinkommen^2) + I(logEinkommen^3) + I(Alter*Weiblich) + I(Alter*logEinkommen) + I(Weiblich*logEinkommen), family="binomial")
summary(modgruen1)
```
Der Interaktionsterm von Alter und Weiblich hat den größten P-Wert und wird aus dem Modell entfernt.
```{r}
modgruen2 = glm(waehleGruen ~ Weiblich + Alter + I(Alter^2) + I(Alter^3) + logEinkommen + I(logEinkommen^2) + I(logEinkommen^3) + I(Alter*logEinkommen) + I(Weiblich*logEinkommen), family="binomial")
summary(modgruen2)
```
Alter^3 hat den höchsten P-Wert und wird aus dem Modell entfernt.
```{r}
modgruen3 = glm(waehleGruen ~ Weiblich + Alter + I(Alter^2) + logEinkommen + I(logEinkommen^2) + I(logEinkommen^3) + I(Alter*logEinkommen) + I(Weiblich*logEinkommen), family="binomial")
summary(modgruen3)
```
Alter hat zwar den höchsten P-Wert, da allerdings sowohl Alter^2, als auch der Interaktionsterm von Alter und logEinkommen hoch signifikant sind, wird auch der lineare Einfluss beibehalten. Stattdessen wird der Interaktionseffekt von Weiblich und logEinkommen entfernt, da dieser nicht signifikant ist.
```{r}
modgruen4 = glm(waehleGruen ~ Weiblich + Alter + I(Alter^2) + logEinkommen + I(logEinkommen^2) + I(logEinkommen^3) + I(Alter*logEinkommen), family="binomial")
summary(modgruen4)
```
Nun sind alle Variablen stark signifikant (außer Alter, welches aus den bereits erläuterten Gründen im Modell bleibt).

#### Dieser Output lässt folgende Interpretationen zu:
Die Odds Grün zu wählen sind bei einer Frau um den Faktor e^0.3615 = 1,435 also ca. 43,5 % höher.
Der Effekt von Alter ist etwas komplizierter. Da der quadratische Term sehr signifikant ist und der lineare nicht, und der quadratische Term ein negatives Vorzeichen hat, scheint es so als würde die Wahrscheinlichkeit grün zu wählen mit zunehmendem Alter bis zu einem gewissen Punkt steigen und dann wieder sinken.
Der Effekt des logEinkommens ist am kompliziertesten, da der lineare Term ein negatives, der quadratische ein positives und der kubische wieder ein negatives Vorzeichen hat.
Dies ergibt aber in Anlehnung an die explorative Datenanalyse auch Sinn, da die Wahrscheinlichkeit zuerst einen abnehmenden Verlauf bei zunehmendem, aber sehr geringem Einkommen zeigte, ab einer gewissen Schwelle aber wieder anstieg und bei noch höheren Einkommen wieder abnehmende war.
Sehr interessant ist der signifikante Interaktionseffekt von Alter und logEinkommen. Aus diesem ist zu schließen dass ältere, wohlhabende Personen eine erhöhte Wahrscheinlichkeit zeigen die Grünen zu wählen. Dies widerspricht dem Klischee vom "intellektuellen Mittelschicht-Grünwähler" oder vom "armen Studenten" der grün wählt.

#### Nichtparametrische Regression:
Zur nichtparametrischen Regression wurden GAMs gewählt, da diese als Summe von Splines und linearen Prädiktoren die größte Modellflexibilität bieten.
```{r}
library(mgcv)
modgruengam = gam(waehleGruen ~ Weiblich + s(Alter) + s(logEinkommen), bs="ps", family="binomial")
summary(modgruengam)
plot(modgruengam)
```
Die Modellierung des Einflusses der Variablen Alter und logEinkommen wurde der Funktion überlassen. Die Variable Weiblich geht als Dummy variable nur linear in die Modellgleichung ein.
Die Variable Weiblich hat einen ähnlichen Koeffizienten wie im parametrischen Modell. Weiterhin ist die 
die Wahrscheinlichkeit, dass eine Frau die Grünen wählt also höher, als die, dass ein Mann die Grünen wählt. 
Die Effekte der Variablen Alter und logEinkommen sind mit dem Output nicht mehr so einfach zu interpretieren.
Allerdings deckt sich der grafische Output mit den bisherigen Erkenntnissen. Der Plot zu Alter zeigt eine Funktion, die einem Polynom zweiten Grades, wie im parametrischen Modell sehr ähnelt. Der Funktionswert, welcher sich letztendlich in der Wahrscheinlichkeit Grün zu wählen über die monotone Transformation der logistischen Funktion widerspiegelt, nimmt bei zunehmendem Alter bis ca. zum 40. Lebensjahr zu und danach ab.
Für die Variable logEinkommen zeigt sich der bereits bekannte Verlauf. Bei sehr niedrigem Einkommen und Einkommen der "oberen Mittelschicht" ist ein hoher Funtkionswert erkennbar, bei geringen und sehr hohen Einkommen nimmt dieser wieder ab.

##### Wahl zwischen den Modellen:
Nun ist zwischen dem parametrischen und nicht parametrischen Modell zu wählen. Um die Modellgüte auch quantitaiv vergleichen zu können, kann bspw. das AIC genutzt werden.
```{r}
library(mgcv)
modgruengam = gam(waehleGruen ~ Weiblich + s(Alter) + s(logEinkommen), bs="ps", family="binomial")
modgruengam$aic

modgruen4 = glm(waehleGruen ~ Weiblich + Alter + I(Alter^2) + logEinkommen + I(logEinkommen^2) + I(logEinkommen^3) + I(Alter*logEinkommen), family="binomial")
modgruen4$aic
```
Es zeigt sich, dass das parametrische Modell sogar ein etwas niedrigeres AIC erreicht als das nichtparametrische.
Zudem ist die Nutzung parametrischer Modelle für weitere Analysen soweie die Interpretation und generelle Handhabung etwas einfacher. Deshalb wird sich an dieser Stelle für die Nutzung des parametrischen Modells entschieden.

### Was hat im Jahr 2005 die typische Grünwählern:in ausgemacht?
Um einen ersten Eindruck zu gewinnnen, wurde die parametrische Regressionsfunktion sozusagen maximiert.
Hierzu werden zuerst die angepassten Werte berechtnet, um Auschluss über die erklärenden Variablen zu erhalten, welche zu dem größten Funktionswert geführt haben.

```{r}
modgruen4 = glm(waehleGruen ~ Weiblich + Alter + I(Alter^2) + logEinkommen + I(logEinkommen^2) + I(logEinkommen^3) + I(Alter*logEinkommen), family="binomial")

waehleGruenhat = plogis(modgruen4$coefficients[1] + modgruen4$coefficients[2]*Weiblich + modgruen4$coefficients[3]*Alter + 
  modgruen4$coefficients[4]*(Alter^2) + modgruen4$coefficients[5]*logEinkommen + modgruen4$coefficients[6]*(logEinkommen^2) + 
    modgruen4$coefficients[7]*(logEinkommen^3) + modgruen4$coefficients[8]*(Alter*logEinkommen))

which.max(waehleGruenhat)

Alter[1945]
Weiblich[1945]
logEinkommen[1945]

exp(1.79176)
```
Die Person, welche gemäß dem Modell 2005 die höchste Wahrscheinlichkeit hatte die Grünen zu wählen war eine 25 jährige Frau mit einem Jahreseinkommen von ca. 6.000 €. Dies spricht sehr dafür, dass diese Person noch nicht Berufstätig war, sondern wahrscheinlich studiert hat. Dieses Ergebnis untermauert somit das Klischee, dass besonders junge Menschen, möglicherweise Studenten, die Grünen wählen.

Um nicht nur die Person mit der maximalen Wahrscheinlichkeit beschreiben zu können sondern ein auch ein allgemeineres Verständnis über die typische Grünenwähler:in 2005 zu erhalten, hilft eine grafische Repräsentation des Modells.

Hierzu werden zu den Variablen Alter und logEinkommen separate Plots erstellt.
#### 1. Alter:

```{r}
x = Alter
modgruenalter = glm(waehleGruen ~ Alter + I(Alter^2), family="binomial")
plot(Alter,waehleGruen, pch=19, bty="n", main="Effekt des Alters", ylab="Wahrscheinlichkeit Grün zu wählen", xlab="Alter")
curve(plogis(modgruenalter$coefficients[1]+modgruenalter$coefficients[2]*x+modgruenalter$coefficients[3]*(x^2)), add=TRUE, lwd=2, col="#1fa12d")
abline(h=0.13)
```

Besonders hoch ist die Wahrscheinlichkeit also für Menschen zwischen 25 und 45 Jahren.

#### 2. Einkommen:

```{r}
x = logEinkommen
plot(logEinkommen,waehleGruen, pch=19, bty="n", main="Streudiagramm", ylab="Wahrscheinlichkeit Grün zu wählen", xlab="logarithmiertes Einkommen")
modeink = glm(waehleGruen ~ logEinkommen + I(logEinkommen^2) + I(logEinkommen^3), family=binomial)
curve(plogis(modeink$coefficients[1] + modeink$coefficients[2]*x + modeink$coefficients[3]*x^2 + modeink$coefficients[4]*x^3), 
      add=TRUE, lwd=2, col="#1fa12d")
abline(h=anteilges)
abline(v=2.15)
abline(v=3.6)
abline(v=4.7)
```

```{r}
exp(2.15)
exp(3.6)
exp(4.7)
```

Die Wahrscheinlichkeit Grün zu wählen in Abhäniggkeit vom Einkommen stellt sich etwas komplizierter dar. Sie ist überdurchschnittlich hoch für Einkommen unter 8500 € sowie Einkommen zwischen 37.000 und 109.000 €.

#### Zusammenfassung:

Unter Zuhilfenahme dieser Plots lässt sich der typische Grün Wähler im Jahre 2005 recht gut charakterisieren:
Tatsächlich ist der typische Grünwähler die typische Grünwählerin, da die Wahrscheinlichkeit, dass Frauen Grün wählen deutlich höher ist.
Sie ist im Alter zwischen 25 und 45 Jahren, was sich sehr gut mit der Person mit maximaler Wahrscheinlichkeit im Alter von 25 Jahren deckt.
Zudem ist ein geringes Einkommen unter 8500 € pro Jahr, oder ein durchschnittliches bis hohes Einkommen
von ca. 37.000 € - 109.000 € pro Jahr typisch für Grünwähler:innen
Auf eine weitere Interpretation dieser Maßzahlen bspw. im Kontext von sozialen Niveaus wird hier verzichtet.





